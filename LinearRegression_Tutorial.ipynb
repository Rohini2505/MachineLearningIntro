{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Tutorial\n",
    "===\n",
    "\n",
    "Some problems don't have discrete (categorical) labels (e.g. color, plant species), but rather a continuous range of numbers (e.g. length, price). For these types of problems, regression is usually a good choice. Rather than predicting a categorical label for each example, it fits a continuous line (or plane, or curve) to the data in order to give a predicition as a number. \n",
    "\n",
    "If you've ever found a \"line of best fit\" using Excel, you've already used regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "===\n",
    "Tell matplotlib to print figures in the notebook. Then import numpy (for numerical data), matplotlib.pyplot (for plotting figures), linear_model (for the scikit-learn linear regression algorithm), datasets (to download the Boston housing prices dataset from scikit-learn), and cross_validation (to create training and testing sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets # Import the linear regression function and dataset from scikit-learn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Print figures in the notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import the dataset\n",
    "===\n",
    "Import the dataset and store it to a variable called iris. Scikit-learn's explanation of the dataset is [here](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html). This dataset is similar to a python dictionary, with the keys: ['DESCR', 'target', 'data', 'feature_names']\n",
    "\n",
    "The data features are stored in boston.data, where each row is data from a suburb near boston, and each of the 13 columns is a single feature. The 13 feature names (with the label name as the 14th element) are stored in boston.feature_names, and include information such as the average number of rooms per home and the per capita crime rate in the town. Labels are stored as the median housing price (in thousands of dollars) in boston.target.\n",
    "\n",
    "Below, we load the labels into y, the data into X, and the names of the features into featureNames. We also print the description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "y = boston.target\n",
    "X = boston.data\n",
    "featureNames = boston.feature_names\n",
    "\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create Training and Testing Sets\n",
    "---\n",
    "\n",
    "In order to see how well our classifier works, we need to divide our data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Visualize The Data\n",
    "===\n",
    "\n",
    "There are too many features to visualize the whole training set, but we can plot a single feature (e.g. average numbe of rooms) against the average housing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,5], y_train)\n",
    "plt.ylabel('Average Houseing Price')\n",
    "plt.xlabel('Avearge Number of Rooms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train A Toy Model\n",
    "===\n",
    "\n",
    "Here we train the regression on a single feature, then plot the linear regression line on top of the data. We do this by first fitting the regression model on our training data, and then predicting the output of the model for that same training data. These predictions are plotted as a line on top of the training data. \n",
    "\n",
    "This can't tell us how well it will perform on new, unseen, data, but it can show us how well the line fits the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "x_train = X_train[:,5][np.newaxis].T # regression expects a (#examples,#features) array shape\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_train, regr.predict(x_train), c='r')\n",
    "plt.ylabel('Average Houseing Price')\n",
    "plt.xlabel('Avearge Number of Rooms')\n",
    "plt.title('Regression Line on Training Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Toy Model\n",
    "===\n",
    "\n",
    "Next, we will test the ability of our model to predict the average housing price for the neighborhoods in our test set, using only the average number of rooms.\n",
    "\n",
    "First, we get our predictions for the training data, and plot the predicted model on top of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = X_test[:,5][np.newaxis].T # regression expects a (#examples,#features) array shape\n",
    "predictions = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x_test, predictions, c='r')\n",
    "plt.ylabel('Average Houseing Price')\n",
    "plt.xlabel('Avearge Number of Rooms')\n",
    "plt.xlabel('Avearge Number of Rooms')\n",
    "plt.title('Regression Line on Test Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate how well our model worked on the training dataset. Unlike with discrete classifiers (e.g. KNN, SVM), the number of examples it got \"correct\" isn't meaningful here. We may care if it is thousands of dollars off, but do we care if it's a few cents from the correct answer?\n",
    "\n",
    "There are many ways to evaluate a linear classifier, but one popular one is the mean-squared error, or MSE. As the name implies, you take the error for each example (the distance between the point and the predicted line), square each of them, and then add them all together. \n",
    "\n",
    "Scikit-learn has a function that does this for you easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "print('The MSE is ' + '%.2f' % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE isn't as intuitive as the accuracy of a discrete classifier, but it is highly useful for comparing the effectiveness of different models. Another option is to look at the $R^2$ score, which you may already be familiar with if you've ever fit a line to data in Excel. A value of 1.0 is a perfect predictor, while 0.0 means there is no correlation between the input and output of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2score = r2_score(y_test, predictions)\n",
    "\n",
    "print('The R^2 score is ' + '%.2f' % r2score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train A Model on All Features\n",
    "===\n",
    "\n",
    "Next we will train a model on all of the available features and use it to predict the housing costs of our training set. We can then see how this compares to using only a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "predictions = regr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print('The MSE is ' + '%.2f' % mse)\n",
    "\n",
    "r2score = r2_score(y_test, predictions)\n",
    "print('The R^2 score is ' + '%.2f' % r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
